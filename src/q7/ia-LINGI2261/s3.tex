\section{Chapter 3.5 to 3.6: Informed search}

\textbf{Attention, Attention: This synthesis must be completed with the content of the book}

On the previous algorithm, we didn't use any information about the solution, in \textit{informed search} we are going to exploit informations on the node to make a decision.

\begin{description}
\item[Informed search] we search using problem specific knowledge and find and/or deduce information about future states and future paths.
\end{description}

We are going to use an evaluation function $f(n)$ that evaluates if the node $n$ is a good candidate to expand (select the node that minimize $f(n)$). Take care that this is an \textbf{evaluation} function \textbf{not the exact} distance.\footnote{If it was the exact distance, we would already know if we are (or not) on the solution path, and we would never have to change direction at any point during the search.}

\subsection{Best-first search}

BFS is afamily of search methods on trees and graphes. It is the same algorithm that we saw earlier, but we add the \textit{evaluation function} in the \textcolor{red}{priority queue}.

Two example:
\begin{itemize}
\item Greedy best-first search
\item A*
\end{itemize}

\subsection{Heuristics functions}

A \textbf{heuristic function}, denoted $h(n)$, is the estimated cost of the node to the goal.\footnote{$f(n)=g(n)$} Obviously we don't know this cost, so we'll have to approximate it. You have to define the heuristic function for each problem you'll have to solve. 

\begin{description}
\item[Optimistic heuristic] an admissible heuristic
\item[Admissible heuristic] it never overestimates the cost of reaching the goal, i.e. the cost it estimates to reach the goal is not higher than the lowest possible cost from the current point in the path.\cite{wikiadmheur} \textbf{TODO: explain properly}
\item[Consistent heuristic] The estimation from a node $n$ to the goal, is lesser than the cost\footnote{Not an estimation, the exact cost} from $n$ to a new node $n'$ with the estimation from the node $n'$ to the goal ($h(n) \leq c(n,a,n')+h(n')$).
    Consistent heuristic is admissible.
\item[Contour] a countour is a set of nodes with $f(n) \leq$ some fixed value
\end{description}

\subsection{Algorithm: Greedy best-first search}

This algorithm calculate directly the heuristic using only the evaluated distance. It ain't good because you don't take into account the path cost and you may come to no solution at all. 

\begin{figure}[H]
\centering
\begin{tabular}{|llll|}
\hline
\textbf{Complete} & \textbf{Time complexity} & \textbf{Space complexity} & \textbf{Optimal} \\
\hline
No& $O(b^m)$ & $O(b^m)$ & No\\
\hline
\end{tabular}
\caption{Greedy best-first search analysis}
\end{figure}

\subsection{Algorithm: A* Search}

A* use the distance and add the current solution path cost. Let $g(n)$ be the cost of the solution going to the node $n$ and $h(n)$ a heuristic function.
$$f(n) = g(n) + h(n)$$
$h(n)$ must never overestimates the cost to reach a goal (and so $f(n)$ also never overestimates the cost). If $n$ is the goal node, then $h(n) = 0$.

\begin{figure}[H]
\centering
\begin{tabular}{|llll|}
\hline
\textbf{Complete} & \textbf{Time complexity} & \textbf{Space complexity} & \textbf{Optimal} \\
\hline
Yes & $O(b^m)$ & $O(b^m)$ & Yes\\
\hline
\end{tabular}
\caption{A* search analysis}
\end{figure}

This is a nice algorithm, but we have a space complexity issue, it takes a lot of memory.

\subsubsection{Proof of A* optimality}

Let $G$ be a goal node in the fringe, but in a suboptimal path. Its path cost $g(G)=C$ is not the lowest one\footnote{$\exists C^* : C > C^*$}. We use the formula at line (1), then as $G$ is a goal node and $h$ is admissible we have line (2). 
\begin{eqnarray}
f(G) &=& g(G) + h(G)\\
h(G) &=& 0\\
f(G) &=& g(G)\\
&=& C > C^*\\
f(G) > C^*
\end{eqnarray}
Let $n$ be a node in the fringe, with $n$ in the path to the optimal soluation (cost $C^*$). As $h$ is admissible, we have $f(n) = g(n) + h(n) \leq C^*$. Then we have
$$f(n) \leq C^* < f(G)$$
In this scenario, $G$ will never be selected, so the hypothesis is absurd. In conclusion \textbf{A* expands no nodes with} $f(n) > C*$.
\subsubsection{Properties of A*}

Here are the properties of A*:
\begin{itemize}
\item With $h(n)$ consistent, the sequence of nodes expanded by A* using \textbf{Graph-Search} is in non decreasing order of $f(n)$
\item A* (using \textbf{Graph-Search}) is optimal if $h(n)$ is consistent
\item A* expands all nodes with $f(n) < C^*$ ($C*$ beeing the optimal cost)
\item A* expands some (at least one) of the nodes on the $C^*$ countour before finding the goal
\item A* expands no nodes with $f(n) > C^*$ 
\end{itemize}

\subsection{Algorithm: Iterative deepening A* (IDA*)}

We combined the algorithm A* with the Iterative deepening. Let $l$ be a limit. \textbf{TODO}

\begin{figure}[H]
\centering
\begin{tabular}{|llll|}
\hline
\textbf{Complete} & \textbf{Time complexity} & \textbf{Space complexity} & \textbf{Optimal} \\
\hline
Yes & Exponetial & \textbf{\textit{linear}} & Yes\\
\hline
\end{tabular}
\caption{IDA* search analysis}
\end{figure}

It's a nice algorithm, but we can still improve the algorithm. With an infinite amount of memory, A* would be the best algorithm. If I agree to re-do some operations IDA* is the best. So we use A* and when we are short of memory we switch to IDA*.\footnote{We called this one \textit{Simple memory-bounded A*}}

\subsection{Monotonicity of $f(n)$}

If $h(n)$ is consistent (Let a be an action and n,n' two nodes we have $h(n) \leq c(n,a,n') + h(n')$) then $f(n)$ along any path is non decreasing.

\subsubsection{Proof}

Suppose that $n'$ is successor of $n$. We have
\begin{eqnarray*}
g(n') &=& g(n) + c(n,a,n')\\
f(n') &=& g(n') + h(n')\\
&=& g(n) + c(n,a,n') + h(n')\\
c(n,a,n') +h(n') &\geq& h(n)\\
g(n) + c(n,a,n') + h(n') &\geq& g(n) + h(n)\\
&\geq& f(n) \\
f(n') &\geq& f(n)
\end{eqnarray*}

\subsection{Comparing two heuristics}

To compare two heuristics you may use:
\begin{itemize}
\item The number of generated nodes $N$
\item The effective branching factor $b^*$, with $N+1 = 1 + b^* + (b^*)^2 + ... + (b^*)^d$ (an ideal $b^*$ is close to one)
\end{itemize}

\subsection{Designing heuristics}

You must choose an \textit{admissible} and \textit{consistent} heuristic. You must choose the most dominant heuristics\footnote{The most dominant is the one with the most informations}. 
