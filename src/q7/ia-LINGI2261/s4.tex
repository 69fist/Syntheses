\section{Chapter 4.1: Local Search}

A search is the operation of looking for a solution where solution is a path from start to goal. We've seen two kind of search, an \textit{uninformed search} in which no prediction is available about the cost of the path. And an \textit{informed search}, where we can estamite the cost of the solution.

What if the path is not important, but only the goal? \textbf{Local search} will not keep track of paths. It has sereval advantages
\begin{itemize}
\item Use a small amount of memory,
\item They can find soluton in infinite search,
\item They find a reasonable (not optimal) solution.
\end{itemize}

\subsection{How does it work?}

You always improve the current solution (we always store the best solution at every iteration). Then we check in the neighbourhood if there is a better solution. If a best solution exists, you restart from this point.

\subsection{Optimization Problem}

We have an \textbf{objective function} that you can \textit{minimize} or \textit{maximize}. Ex: \textit{distance to position}, \textit{number of queen attacking in the 8 queens problem}, ...

The only problem of this algorithm are \textbf{local optimal}, so you may be stuck at some point in the search. 

\subsubsection{Neighbourhood size}

If we choose to take larger neighbourhood we will have \textit{shorter path} to the solution, but we will also need \textit{more time} to explore all possibilities. It's a \textbf{key design decision}.

\subsubsection{Neighbourhood connectivity}

In a \textbf{connected neighbourhood}, there is a path to an optimal solution, from each solution. It has two advantages
\begin{itemize}
\item Convergence property
\item No need of restarting strategy (you will never be block)
\end{itemize}

\subsubsection{Neighbourhood constraint}

\textit{How to combine faisability with optimality requirements?} Two approaches are possible:
\begin{itemize}
\item
	\begin{enumerate}
	\item Maintain feasibility at all times
	\item Explore only feasible solutions
	\end{enumerate}
\item 
	\begin{enumerate}
	\item Do not maintain feasibility at all time; relax a subset of the constraints
	\item Explore a larger search space
	\item Drive the search to high quality and feasible solutions
	\end{enumerate}
\end{itemize}

\subsection{Heuristics and metaheuristics}

\begin{description}
\item[Heuristics] Drive the search towards \textit{local optimum}, it's a memoryless solution
\item[Metaheuristics] Drive the search towards \textit{global optimality}, it includes memory or learning
\item[Systematic heuristics] Exploration (possibly partial) of the neighborhood to determine the next solution
\end{description}

\subsection{Hill climbing}

Select a starting state, and move in the direction of increasing value. Stop the iteration when it's impossible to go further. This algorithm has multiple issues:
\begin{itemize}
\item Local maximum
\item Plateau (a flat area)
\item Ridges
\end{itemize}

\subsubsection{Variants}

There is multiple variants of the hill climbing algorithm.
\begin{description}
\item[Stochastic hill climbing] randomly choose in the list of possibilites
\item[First-choice hill climbing] pick the first good successor you find (useful when there is a large amount of possibilites)
\item[Random restart] You start from multiple random points
\end{description}

\subsubsection{Analysis}

Hill climbing has a big Achilles hell, the local maximas. You cannot escape local maxima, considering that hill climbing \textbf{will never makes downhill moves}.

\subsection{Random walks}

You can consider another kind of heuristic, in which you select randomly an element of the neighborhood and decide whether to accept it as the next solution. There is two possibles approches: \textit{random improvement} and \textit{metropolis heuristic} \textbf{TODO Complete with the book}.

\subsection{Metaheuristic}

We've already defined what \textit{metaheuristic} consist of, in this subsection we are going to give some examples of \textit{metaheuristic}. Here are somme examples:
\begin{enumerate}
\item \textbf{Simulated annealing}: \textbf{TODO complete with algorithm}

	This technique use a analogy with metallurgy, in which you want molecules to find a stable location relative to neighbors, and to do so you heat the metal causing mollecules to take on undesirable locations. During cooling the molecules reduce their movement and settle into a more stable position. \textit{Annealing} is the process of heating metal and letting it cool slowly to lock in the stable locations of the molecules. So here is the principle of this technique:
	\begin{enumerate}
		\item Always move uphill if possible (hill climbing)
		\item Sometimes go downhill (like in metallurgy when temperature is high).
		\item Optimality is guaranteed with slow annealing schedule. 
	\end{enumerate}

\item \textbf{Local Beam Search}:
	
	Hill climbing and simulated annealing techniques keep one state in memory. In this technique you keep $k$ states in memory. \textbf{TODO explain the advantage ?!}

\item \textbf{Genetic Algorithms}:

	Algorithm that use the idea of evolution.
	\begin{enumerate}
		\item Start with $k$ initial guesses forming a population
		\item Each individual from the population has a DNA (fixed-length string) and a fitness score
		\item Produces the next generation by reproduction between the best individuals from current population
		\item Add a few random mutations (not too much, or risk to screw up a good solution)
	\end{enumerate}
	The only issues with this algorithm is that crossover is not applicable to all problems.

\item \textbf{Tabu search Metaheursitics}:
	
	You select the best neighbor that has not yet been visited and only maintain the recent visited node, not all of them. 
\end{enumerate}

\subsection{Intensification vs Diversification}

\begin{itemize}
\item \textbf{Intensification}:

	\begin{description}
		\item[Goal] increase search around promising areas
		\item[Risk] premature convergence
		\item[Mean] favor good solutions
	\end{description}

\item \textbf{Diversification}:
	 
	\begin{description}
		\item[Goal] explore new ares
		\item[Risk] convergence to optimality may be too long
		\item[Mean] probabilistic choice of solutions
	\end{description}

\subsection{Other local search Approaches}

There is a bunch of other local search:
\begin{description}
\item[Variable Neighborhood Search] sequence of neighborhood
\item[Guided local search] use a sequence of objective functions to drive away from local optima
\item[Adaptive local Search] The heuristics/metaheuristisc are dynamically adapted during the search
\item[Ant colony optimization] the selection function is updated
\item[Statistic Local Search] another name for Local search, stressing the stochastic aspect of the search
\end{description}

\end{itemize}



