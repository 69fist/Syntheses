\input{../../lib.tex}

%\theoremstyle{definition}
%\newtheorem{mydef}{Définition}
%\newtheorem{mynota}[mydef]{Notation}
%\newtheorem{myprop}[mydef]{Propriétés}
%\newtheorem{myrem}[mydef]{Remarque}
%\newtheorem{myform}[mydef]{Formules}
%\newtheorem{mycorr}[mydef]{Corrolaire}
%\newtheorem{mytheo}[mydef]{Théorème}

\DeclareMathOperator{\res}{Res}

\hypertitle{Math\'ematique}{3}{1103}{Benoît Legat}{Benoît Legat}

\part{Equation à dérivée partielles (EDP)}
\begin{myrem}
  Ce cours traite des fonction qui ont un sens physique donc
  on a souvent besoin d'écrire que
  \[ \lim_{x\to\infty} u = \lim_{y\to\infty} u = 0. \]
  Ce n'est néanmoins pas tout le temps vrai.
  Par exemple, si $u$ est solution d'une équation de diffusion,
  vous ne pouvez pas dire que
  \[ \lim_{t\to\infty} u = 0 \]
  car l'intégrale de $u$ doit être conservée au cours du temps.

  Cependant, on peut tout le temps supposer que $u$ n'est jamais
  infini, même quand $t$ ou $x$ tendent vers l'infini.
  Sauf dans le cas d'un Dirac (voir annexe~\ref{app:dirac}), bien entendu.
\end{myrem}
\section{EDP du premier ordre}
Une EPD du premier ordre est une équation de la forme
\[ P(x, y)\fpart{u(x, y)}{x}
  + Q(x, y)\fpart{u(x, y)}{y}
  = R(x, y, u) \]
avec $P, Q, R$ des fonctions continues. % FIXME do I need it ?
$P$ et $Q$ peuvent aussi dépendre de $u$.
Dans ce cas,
on dit que l'EDP est \emph{quasi-linéaire} et
la méthode présentée ici ne marche pas toujours.
On va traiter un cas d'EDP \emph{quasi-linéaire}
dans la section~\ref{sec:traffic} où on s'en sort tout de même
car on a $R = 0$.

On remarque que l'équation se réécrit comme suit
\begin{equation}
  \label{eq:pqrn}
  \left(P, Q, R\right) \cdot \left(
  \fpart{u}{x}, \fpart{u}{y}, -1\right) = 0.
\end{equation}

Où $\left(\fpart{u}{x}, \fpart{u}{y}, -1\right)$ est connu pour être normal
à $u$ au point $\left(x, y, u(x, y)\right)$.
Par \eqref{eq:pqrn}, on a donc que $(P, Q, R)$ est perpendiculaire à la normale
c'est à dire qu'il est tangent au graphe de $u$.

$(P, Q, R)$ forme donc un champ de vecteur tangent au graphe de $u$.
Mais comment construire $u$ à partir de ce champ ?

On remarque que comme $P$, $Q$ et $R$ sont continues, deux vecteurs proches
seront presque parallèles. Le champ est donc composé de courbes l'une à côté
de l'autre.

Pour déterminer $u$, la technique est de commencer par trouver ces courbes
dans le plan $xy$ puis de leur ajouter leur hauteur $u$.
On appelle ces courbes les \emph{courbes caractéristiques}.

\subsection{Nécessité de conditions initiales}
On connait les tangentes à $u$, on sait donc construire une
sorte de coque mais à quelle hauteur mettre cette coque ?
Aussi, comment agencer ces courbes caractéristiques l'une à côté de l'autre.
En effet, le champ de vecteurs formé par $(P, Q, R)$ est formé de vecteurs
qui sont parallèles lorsqu'ils sont très proches.
Si on a nos courbes caractéristiques, notre coque est encore maléable,
on peut déplacer ces courbes de haut en bas par rapport à une autre.

En donnant une condition initiale qui coupe une et une seule fois chaque
courbe caractéristique, on détermine tout cela.
Notons $\Gamma$, cette courbe parametrée en fonction de $s$
\[ \Gamma \equiv (x(s), y(s)). \]
On connait le long de cette courbe $u(x(s), y(s)) = f(s)$.

\subsection{Détermination des courbes caractéristiques}
On cherche une courbe dont $(P, Q)$ est tangent c'est à dire que
\[ \fdif{y}{x} = \frac{Q}{P} \]
Le long de ces courbes, on a donc
\[ P(x, y)\dif y = Q(x, y) \dif x. \]
Il peut être judicieux ici de ne se retrouver avec que du $y$ à gauche
et que du $x$ à droite
\begin{align*}
  P'(y) \dif y & = Q'(x) \dif x & \frac{P'(y)}{Q'(x)} = \frac{P(x,y)}{Q(x,y)}
\end{align*}
Pour déterminer ces courbes, il nous faut utiliser la condition initiale, donc
\[ \int_{y' = y(s)}^{y' = y} P'(y') \dif y'
= \int_{x' = x(s)}^{x' = x} Q'(x') \dif x' \]
où $x'$ et $y'$ sont des variables introduites juste pour l'intégration
car on a déjà $x$ et $y$ aux bornes donc on ne peut pas les utiliser pour
intégrer.

On arrive donc à une équation $g_s(x, y) = 0$ que $x$ et $y$ doivent
respecter pour être sur la courbe caractéristique passant par $(x(s), y(s))$.

\subsection{Détermination de $u$ le long des courbes caractéristiques}
On doit maintenant déterminer $u$ le long de ces courbes.
Pour ce faire, on va réutiliser le champ de vecteur $(P, Q, R)$ et sa
tangence au graphe de $u$. % TODO orthographe tangeance
On va intégrer \emph{le long d'une caractéristique} où on a
une équation $g_s(x, y) = 0$ qu'on a trouvé au point précédent
qui est respectée
\begin{align*}
  P \dif u & = R \dif x\\
  Q \dif u & = R \dif y.
\end{align*}
Ces deux équations sont équivalentes car, comme on est le long des
caractéristiques, $P \dif y = Q \dif x$.

On peut maintenant choisir la plus simple,
sans perte de généralité, disons que c'est la première et
on va faire la même manipulation qu'au point précédent
\[ P'(u) \dif u = R'(x, y) \dif x. \]
On peut maintenant utiliser la condition initiale $u(s)$ pour
déterminer la hauteur des courbes caractéristiques
\[ \int_{u' = f(s)}^{u' = u(x,y)} P'(u') \dif u'
= \int_{x' = x(s)}^{x' = x} R'(x', y_s(x')) \dif x'. \]
où $y_s(x')$ est la valeur de $y$ lorsque $x = x'$
sur la courbe caractéristique respectant $g_s(x, y) = 0$.

\begin{myrem}[$s$ est constant]
  Il est important de bien réaliser que, lors de l'intégration,
  $s$ est bien constant et ne dépend pas de $x'$.
  On intègre sur \emph{une} caractéristique
  (celle qui passe par $(x(s), y(s))$ et qui respectent donc
  $g_s(x', y') = 0$), c'est d'ailleurs pour insister sur ça que je mets
  $s$ en indice de $f$ et pas en argument.
  Il est d'ailleurs inutile de développer $f(s)$ ici si on nous donne
  son équation.
\end{myrem}

On arrive à une équation de $u(x, y)$ dépendant de $x$ et $s$.
Il faut maintenant isoler $s$ dans la condition $g_s(x, y) = 0$ et trouver
$s(x, y)$.
On remplace alors, dans l'expression de $u(x, y)$, $s$ par $s(x, y)$.

\subsection{Équation de densité de traffic}
\label{sec:traffic}
Soit
\begin{itemize}
  \item $\rho(x, t)$, le nombre de véhicules par \meter en $x$ au temps $t$;
  \item $u(x, t)$, la vitesse des véhicules en $x$ au temps $t$;
  \item $N(x_0, x_1, t)$, le nombre de véhicules entre $x_1$ et $x_2$
    au temps $t$.
\end{itemize}
On peut écrire
\begin{align}
  \label{eq:Nrho}
  N(x_0, x_1, t) & = \int_{x_0}^{x_1} \rho(x, t) \dif x\\
  \nonumber
  \fpart{N}{t} & \stackrel{\eqref{eq:Nrho}}{=}
  \int_{x_0}^{x_1} \fpart{\rho(x, t)}{t} \dif x\\
  \nonumber
  \fpart{N}{t} & = u(x_0, t) \rho(x_0, t) - u(x_1, t) \rho(x_1, t)\\
  \nonumber
  & = - \int_{x_0}^{x_1} \fpart{(u\rho)}{x} \dif x.
\end{align}
D'où
\[ \int_{x_0}^{x_1} \fpart{\rho}{t} + \fpart{(u\rho)}{x} \dif x = 0. \]
Comme c'est vrai pour tout intervalle $[x_0, x_1]$, on a
\begin{equation}
  \label{eq:traffic}
  \fpart{\rho}{t} + \fpart{(u\rho)}{x} = 0.
\end{equation}

\subsubsection{Le modèle de Lighthill-Whitham-Richards}
En utilisant le modèle de Lighthill-Whitham-Richards qui
se résume à dire qu'il y a une vitesse et une densité maximale
et que la vitesse diminue linéairement avec la densité du trafic,
autrement dit
\[ u = u_\mathrm{max} \left(1 - \frac{\rho}{\rho_\mathrm{max}}\right) \]
on peut réécrire l'équation~\eqref{eq:traffic} en fonction de $\rho$.

On obtient
\[ \fpart{\rho}{t} + u_\mathrm{max}
\left(1 - \frac{2\rho}{\rho_\mathrm{max}}\right)\fpart{\rho}{x} = 0 \]
où le facteur devant $\fpart{\rho}{x}$ peut être interprété comme la vitesse
de l'\emph{information} car on sait par la méthode des caractéristiques
qu'il vaut la pente des caractéristiques.

On sait que les caractéristiques sont des droites car comme l'équation
est homogène, $\rho$ ne varie pas selon les caractéristiques et cette
pente est donc constante.
\[ \fdif{x}{t} =
u_\mathrm{max} \left(1-\frac{2\rho(s)}{\rho_\mathrm{max}}\right) \]
On remarque que cette vitesse est \emph{négative} si
$\rho > \frac{\rho_\mathrm{max}}{2}$.

\paragraph{Intersection des caractéristiques}
Le problème c'est que, si dans la conditions initiale,
il y a un traffic dégagé suivit d'un traffic dense,
il y aura un choc des caractéristiques.
Cette endroit de choc sera une discontinuité dans la densité du traffic,
on passera de caractéristiques voulant que le traffic soit dégagé à des
caractéristiques voulant un traffic dense.
Ça peut s'apparenter à des voitures rencontrant un bouchon.

Si il y a une discontinuité dans le traffic au départ,
comme dans le cas d'un feu rouge,
\[ \rho_-(x) > \rho_+(x) \]
on peut considérerer que toutes les densités de l'intervalles
$[\rho_-(x); \rho_+(x)]$ se trouvent au point $x$.
Ainsi, on peut faire partir toutes les caractéristiques correspondantes
du point $x$ et on peut recouvrir l'intervalle qui serait créé où
aucune caractéristique ne viendrait donner d'information sur la densité.

\section{EDP du second ordre}
Une EPD du deuxième ordre est une équation de la forme
\[ A \ffpart{\phi}{x} + B\fdpart{\phi}{x}{y} + C\ffpart{\phi}{y} = R \]
où $A$, $B$, $C$ et $R$ sont des fonction régulière qui peuvent
dépendre de $x$, $y$, $\phi$ ou même de $\fpart{\phi}{x}$ ou de
$\fpart{\phi}{y}$.

Le problème est bien posé si et seulement si
\[
  \begin{vmatrix}
    A & B & C\\
    \fdif{x}{s} & \fdif{y}{s} & 0\\
    0 & \fdif{x}{s} & \fdif{y}{s}
  \end{vmatrix}
  \neq 0.
\]

On distingue les EDP de second ordre en 3 cas
\begin{center}
  \begin{tabular}{|l|l|}
    \hline
    $B^2 - 4AC > 0$ & EDP hyperbolique\\
    $B^2 - 4AC = 0$ & EDP parabolique\\
    $B^2 - 4AC < 0$ & EDP elliptique\\
    \hline
  \end{tabular}
\end{center}

\subsection{Équation d'onde}
Une équation d'onde est une EDP hyperbolique dont l'équation est
\[ c^2 \lap \phi = \ffpart{\phi}{t}. \]
En 1D, ça devient
\[ c^2\ffpart{\phi}{x} - \ffpart{\phi}{t} = 0. \]
On sait alors qu'il existe $f_1$ et $f_2$ telles que
\[ \phi(x, y) = f_1(x - ct) + f_2(x + ct). \]

\subsection{Équation de diffusion}
Une équation de diffusion est une EDP parabolique dont l'équation est
\[ \alpha \lap \phi = \fpart{\phi}{t} \]
où $\alpha$ est le coefficient de \emph{diffusivité}.
En 1D, ça devient
\[ \alpha \ffpart{\phi}{x} = \fpart{\phi}{t}. \]

\begin{myrem}[unités de $\alpha$]
  On remarque que comme $\lap \phi$ a des unités de $[\phi]\per\meter\squared$
  et que $\fpart{\phi}{t}$ a des unités de $[\phi]\per\second$,
  $\alpha$ doit avoir des unités de $\meter\squared\per\second$.
\end{myrem}

L'équation de diffusion étale une fonction de départ en gardant
l'intégrale constante.
Elle perd tous les détails de la fonction de départ et n'est donc
pas réversible, c'est à dire que lorsqu'on connait $\phi(t)$, on
peut connaitre $\phi(t + \Delta t)$ uniquement si $\Delta t > 0$.

Si la fonction de départ est un Dirac (voir annexe~\ref{app:dirac})
\[ \phi(x, 0) = Q \delta(x). \]
La solution est une gaussienne
\[ \phi(x, t) = \frac{Q}{\sqrt{\pi4\alpha t}}
\exp\left(-\frac{x^2}{4\alpha t}\right). \]
Si la fonction de départ est une gaussienne
\[ \phi(x, 0) = \phi_0 \exp\left(-\frac{s^2}{b^2}\right), \]
on peut imaginer qu'elle vienne d'un Dirac
\footnote{On n'est pas sûr que ça soit vrai,
comme dit précédemment, une diffusion n'est pas réversible.
Il pourrait y avoir plus de détails qui
ont été effacés mais considérer l'un ou l'autre ne change rien
si on s'intéresse au futur.}.
On a alors nécessairement
\begin{align*}
  b^2 & = 4\alpha t\\
  \phi_0 & = \frac{Q}{\sqrt{\pi4\alpha t}}.
\end{align*}
D'où
\[ \phi(x, t) = \frac{\phi_0b}{\sqrt{b^2 + 4\alpha t}}
\exp\left(-\frac{x^2}{b^2 + 4\alpha t}\right). \]

\subsection{Équation de Laplace}
Une équation de Laplace est une EDP elliptique dont l'équation est
\[ \lap \phi = 0. \]
En 2D, ça devient
\[ \ffpart{\phi}{x} + \ffpart{\phi}{y} = 0. \]
Elle se résout à l'aide d'une séparation des variables.

\subsection{Équation de Poisson}
Une équation de Poisson est une EDP elliptique dont l'équation est
\[ \lap \phi = R. \]
En 2D, ça devient
\[ \ffpart{\phi}{x} + \ffpart{\phi}{y} = R. \]
On remarque que l'équation de Laplace est le cas particulier de
l'équation de Poisson où $R = 0$.

\section{Méthode de séparation de variables}
Nous nous intéressons ici à la méthode de séparation des variables pour les EDP
qui n'est pas la même que celle pour les EDO.

On va supposer qu'il existe deux fontions $X$ et $Y$ telles que
\[ \phi(x, y) = X(x) \cdot Y(y). \]
À partir de cette supposition, il est maintenant possible de résoudre
les EDP plus facilement.

Pour que cette méthode marche, il faut deux choses
\begin{itemize}
  \item L'équation doit être homogène et linéaire;
  \item Le domaine doit se ramener à une domaine rectangulaire
    (ou cubique si on est en 3D)
    avec, si nécessaire, un changement de variable.
\end{itemize}
Pour la 2\ieme{} condition, un changement de variable classique est
celui pour passer d'un cercle à un carré
\[ (x, y) = (r\cos\theta, r\sin\theta). \]
Dans ce cas,
\begin{align*}
  \lap \phi & = \ffpart{\phi}{x} + \ffpart{\phi}{y}\\
  & = \ffpart{\phi}{r} + \frac{1}{r}\fpart{\phi}{r}
  + \frac{1}{r^2}\ffpart{\phi}{\theta}
\end{align*}

Sur les côtés, on pose des conditions limite.
Ces conditions sont soit homogènes, soit non-homogènes.

On peut aussi appliquer la méthode de séparation des variables
avec un domaine infini, dans ce cas on utilise le fait
que $u$ ne peut pas tendre vers l'infini pour éliminer une des
exponentielles qu'on obtient.

\subsection{L'équation de Laplace par séparation de variables}
Supposons qu'on soit dans un rectange.
Il nous faut 4 conditions limites, une sur chaque côté.
Si toutes les conditions limites sont homogènes, la solution est la solution
triviale $\phi = 0$.

On ne sait gérer qu'une seule condition limite non-homogène à la fois.
S'il y en a plusieurs, on les traites successivement en prenant les autres
égales à 0 puis on somme les solutions.
En effet, comme l'équation de Laplace est linéaire, le principe
de superposition s'applique.
Supposons donc par la suite qu'on ait une seule condition limite non-homogène.

\subsubsection{Recherche des solutions}
On peut calculer
\[ \lap \phi = X'' Y + X Y''. \]
On a donc
\[ \frac{X''}{X} + \frac{Y''}{Y} = 0 \]
où on a divisé par $XY$ car on les suppose non-nuls comme on
écarte la solution triviale.

En divisant l'équation par $x$, on a
\[ \fdif{\left(\frac{X''}{X}\right)}{x} = 0 \]
d'où on tire que $\frac{X''}{X}$ est égal à une constante $\pm k^2$
et $\frac{Y''}{Y} = \mp k^2$.
On a ici 3 cas à traiter où on pose $k > 0$
\begin{itemize}
  \item $X'' = k^2X$ qui donne une solution $\phi_1 = X_1Y_1$
    avec $X_1 = Ae^{kx} + Be^{-kx}$ et $Y_1 = C\cos(ky) + D\sin(ky)$;
  \item $X'' = -k^2X$ qui donne une solution $\phi_2 = X_2Y_2$
    avec $X_2 = E\cos(kx) + F\sin(-kx)$ et $Y_2 = Ge^{ky} + He^{-ky}$;
  \item $X'' = 0$ qui donne une solution $\phi_3 = X_3Y_3$
    avec $X_3 = Ix + J$ et $Y_3 = Ky + L$.
\end{itemize}

\subsubsection{Application des conditions limites homogènes}
Posons $\phi_\Sigma = \phi_1 + \phi_2 + \phi_3$.
Que doit-on faire maintenant ?
Appliquer les conditions sur $\phi_1$, $\phi_2$ et $\phi_3$ séparément ou
sur $\phi_\Sigma$ ?
Rappelons nous que rien ne nous indiquait que $\phi$ était effectivement
à variable séparable.
Ici, on a trouvé $\phi_1$, $\phi_2$ et $\phi_3$ qui respectent
l'équation de Laplace, $\phi_\Sigma$ la respecte aussi mais n'est plus
à variable séparable.

Comme rien ne nous impose que $\phi$ soit à variable séparable,
dans le cas général, il faut appliquer les conditions limites sur
$\phi_\Sigma$ et non sur $\phi_1$, $\phi_2$ et $\phi_3$ séparément sinon
on se rajoute une contrainte qui n'existe pas et on perd potentiellement
des solutions.
Seulement, dans la plupart des cas, ça ne change rien
de le faire séparément ou non et ça complique énormément les calculs.
En pratique, une bonne manière de faire est donc d'appliquer
les conditions limites séparément et si plus aucune solution
ne subsiste, appliquer les conditions limites sur $\phi_\Sigma$.
En effet, on a déjà potentiellement perdu des solution avec la supposition
que $\phi$ était à variable séparable, pourquoi ne pas continuer
sur notre lancée ?

En appliquant les conditions limites séparément,
pour les conditions limites homogènes,
on arrive à des équations du style
\[ u(x, 0) = 0 = X(x)Y(0). \]
Si $X(x) = 0$ pour tout $x$, on a la solution triviale, comme elle
est inintéressante, supposons que $\exists x$ tel que $X(x) \neq 0$ et donc
on a $Y(0)$.
Une des deux variables a deux conditions homogènes,
ça permet d'éliminer deux solution.
Par exemple, si c'est $X$ qui a deux conditions homogènes,
on arrive nécessairement à $X_1 = X_3 = 0$
donc $\phi_1$ et $\phi_3$ sont triviaux.

On remarque ici que $\phi_3$ est éliminé dans les deux cas.
En effet, il n'est que utile dans le cas où on applique
les conditions limites sur $\phi_\Sigma$.
Il peut être utile par exemple dans un cas de domaine semi infini où
on veut que $\phi$ ne tende pas vers 0.
Les exponentielles sont alors inutiles car elle tendent
soit vers l'infini, soit vers 0
et les cosinus et les sinus ne convergent pas.
Dans ce cas, si on applique les conditions limite séparément,
on ne trouvera pas de solution et il faudra
l'appliquer sur $\phi_\Sigma$.

En continuant dans notre exemple avec les deux
condition homogène en $x$, supposons que les deux
conditions soient $u(0, y) = 0$ et $u(L, y) = 0$.
On a alors
\begin{align*}
  E & = 0\\
  E\cos(kL) + F\sin(kL) & = 0
\end{align*}
D'où, soit $F = 0$, soit $\sin(kL) = 0$, le premier cas nous
donne la solution triviale, ce qui ne nous intéresse pas.
Le deuxième cas nous restreint les possibilités de $k$,
en se souvenant qu'on a posé que $k > 0$, à
\begin{align*}
  k_n & = \frac{n\pi}{L} & n = 1, 2, \ldots
\end{align*}

Complétons maintenant chacune de ces solution avec la solution
associée pour $Y$.
On a à résoudre
\[ Y_n'' = k_n^2Y_n \]
il est important d'utiliser $k_n$ ici et non $k$
car $X''/X$ et $-Y''/Y$ valent la même constante.

À nouveau, rien ne nous oblige que $\phi$ soit à variable
séparable et en l'imposant on risque de perdre des solutions.
Par le principe de superposition,
la solution générale s'écrit donc maintenant,
\[ X(x) = \sum_{n=0}^{n=\infty} F_n \sin(k_nL)Y_n. \]

\subsubsection{Application de la condition limite non-homogène}
L'astuce ici, c'est de remarquer que les sinus
forment une base orthogonale avec le produit vectoriel
\[ \int_{x = 0}^{x = L} \sin\left(\frac{n\pi}{L} x\right)
\sin\left(\frac{m\pi}{L} x\right) \dif x. \]
En effet, si $n \neq m$, ce produit vectoriel est nul et
si $n = m$, il vaut $\frac{L}{2}$.

Utilisons cela pour calculer $A_m$ avec la condition non-homogène.
Prenons, par exemple, comme condition $u(x, 0) = f(x)$, qui donne
\[ \sum_{n = 1}^{n = \infty} A_n \sin\left(\frac{n\pi}{L} x\right)
= f(x) \]
et en appliquant le produit vectoriel avec
$\sin\left(\frac{m\pi}{L} x\right)$, on a
\[ A_mY_m\frac{L}{2} =
\int_{x=0}^{x=L} \sin\left(\frac{m\pi}{L}x\right) f(x) \dif x \]
D'où
\[ A_mY_m\frac{L}{2} = \frac{
\int_{0}^{L} \sin\left(\frac{m\pi}{L}x\right) f(x) \dif x}
{Y_m\frac{L}{2}}. \]
\begin{myrem}
  Il est primordial ici de se rendre compte qu'on se base sur un
  exemple les conditions limites sont $u(0, y) = 0$ et $u(L, y) = 0$.
  On a donc $k_n = \frac{m\pi}{L}$ et comme bornes pour le produit
  vectoriel 0 et $L$.
\end{myrem}

\part{Analyse complexe}
On a une définition semblable pour la limite et la continuité
pour $f(z)$ que pour les fonctions à plusieurs variables
\begin{mydef}[Limite]
  $\lim_{z\to z_0} f(x) = L$ si et seulement si
  \[ \forall \epsilon>0, \exists\delta>0:
  |z-z_0|<\delta \Rightarrow |f(z)-L|<\epsilon. \]
\end{mydef}
\begin{mydef}[Continuité]
  $f$ est continue en $z_0$ si et seulement si $f$ est définie en $z_0$ et
  \[ \lim_{z \to z_0} f(z) = z_0. \]
\end{mydef}

La définition de la dérivée par contre, est fort différente
et c'est là que réside tout l'intérêt de l'analyse complexe.
En effet, pour les fonctions à plusieurs variables, le dénominateur est
équivalent à $|z - z_0|$ alors qu'ici, c'est $z - z_0$.
\begin{mydef}
  \[ f'(z_0) = \lim_{z \to z_0} \frac{f(z) - f(z_0)}{z - z_0}. \]
\end{mydef}

En pratique, les fonctions usuelles sont continues et dérivables si
on défini les coupures correctement et les règles de dérivations
habituelles sont aussi vérifiées.
Par exemple, $f(z) = z^2$ est continue et dérivable pour tout $z$ et
$f'(z) = 2z$.
Par contre la fonction conjugué $f(z) = \bar{z}$ n'est pas dérivable.

On définit d'ailleurs deux nouveaux termes
\begin{mydef}
  Une fonction $f(z)$ holomorphe est une fonction définie et dérivable
  en tout point d'un sous-ensemble ouvert du plan complexe.
\end{mydef}
\begin{mydef}
  Une fonction $f(z)$ entière est une fonction holomorphe sur tout
  le plan complexe.
\end{mydef}

Comme $f(z)$ a une image complexe,
on peut définir $P$ et $Q$ comme suit $f(z) = P(z) + iQ(z)$.
Définissons aussi $x$ et $y$ comme suit $z = x + iy$.
On a alors le théorème suivant.
\begin{mytheo}[Condition de Cauchy-Riemann]
  $f$ est différentiable si et seulement si
  \[ \left\{\begin{aligned}
      \fpart{P}{x} & = \fpart{Q}{y}\\
      \fpart{Q}{x} & = -\fpart{P}{y}.
  \end{aligned}\right. \]
\end{mytheo}

Un corrolaire direct de ce théorème, c'est que $f$ respecte l'équation
de Laplace $\lap f = 0$.
En effet, on obtient sans mal $\lap P = 0$ et $\lap Q = 0$ d'où
$\lap f = \lap P + i\lap Q = 0$.

Cauchy-Riemann nous permet de montrer
une théorème fort intéressant concernant les intégrales baptisé le
théorème de Cauchy.
\begin{mytheo}[Théorème de Cauchy]
  Soit $f(z)$ holomorphe dans un domaine $D$ ``simplement connexe''.
  On a
  \[ \oint_C f(z) \dif z = 0. \]
\end{mytheo}
De ce dernier, on peut montrer la formule intégrale de Cauchy.
\begin{mytheo}[Formule intégrale de Cauchy]
  Soit $f(z)$ holomorphe dans un domaine $D$. % fermé simple
  On a
  \[ f(z) = \frac{1}{2\pi i}\oint_C
  \frac{f(\zeta)}{\zeta-z} \dif \zeta = 0. \]
\end{mytheo}
Cette formule permet déjà de calculer certaines intégrales.

Le problème du théorème de Cauchy, c'est qu'il ne s'applique qu'aux
fonctions holomorphes à l'intérieur du contour $C$.
Heureusement, il y a moyen de le généraliser avec le théorème suivant.
\begin{mytheo}[Théorème des Résidus]
  Soit $\Omega$ un domaine simplement connexe et $f$ analytique
  sauf en certains pôles $z_1, z_2, \ldots, z_n$.
  On a
  \[ \oint_C f(z) \dif z = 2i\pi\sum_{k=1}^n \res(f, z_k). \]
\end{mytheo}

Il y a deux nouveaux point à aborder pour comprendre ce théorème
magique.
Qu'est-ce qu'un pôle et comment calculer un résidu.

Supposons qu'on ait une singularité $z$.
Elle peut être
\begin{itemize}
  \item soit ``effaçable'', ça veut dire que $f$ reste borné en $z$;
  \item soit un pôle, ça veut dire que $f$ tend vers l'infini en $z$;
  \item soit essentielle, ça veut dire que la limite n'existe pas en $z$.
\end{itemize}

L'idée du théorème des Résidus, c'est que $\oint_C f(z) \dif z$ ne vaut
pas 0 mais la somme des $\frac{1}{2i\pi} \oint_{C_k} f(z) \dif z$ qu'on
nomme $\res(f, z_k)$.
Il suffit donc de calculer ces intégrales.

Pour cela, introduisons un développement en série plus générale qui
part de $-\infty$.
\begin{mydef}[Développement en série de Laurent]
  Soit $f$ analytique sur $D \subseteq \mathbb{C}$,
  le développement en série de Laurent de $f$ autour de $a$ est
  \[ f(z) = \sum_{-\infty}^{\infty}b_n(z-z_0)^n. \]
\end{mydef}
L'avantage de ce développement en série, c'est que
$\oint_C (z-z_0)^j$ est nul pour tout $j \neq -1$ et vaut $2\pi i$ si
$j = -1$.

Le développement de Taylor est le cas particulier de ce développement
pour $f$ analytique.
Ici, $f$ n'est pas analytique car il a un pôle.
L'astuce c'est que pour tout pôle, il existe un plus petit entier
$m$ tel que $H = (z-z_k)^mf$ est analytique sur $C_k$.
On dit alors que $z_k$ est un pôle à l'ordre $m$.

On peut alors calculer Taylor pour $H$ en $z_k$,
le diviser par $(z-z_k)^m$ et ça donne le développement en série de Laurent
de $f$.
En intégrant ce développement en série, on a vu plus haut,
qu'il n'y avait que $b_{-1}$ qui restait,
c'est à dire $c_{m-1}$ dans le développement en série de Taylor de
$H$.
On a donc
\begin{align*}
  b_{-1} & = c_{m-1}\\
  & = \frac{1}{(m-1)!}\lim_{z\to z_k} H^{(m-1)}(z)\\
  & = \frac{1}{(m-1)!}\lim_{z\to z_k} \fdif{^{m-1}}{z^{m-1}}
  \left((z-z_k)^m f(z)\right).
\end{align*}

\begin{mydef}[Résidu d'une fonction] 
  Le résidu d'une fonction $f$ avec un pôle de degré $n$ en $a$ est
  $\res_a f = b_{-1}$.
  Il peut également être obtenu par la formule suivante
  \[ \res_a f = \frac{1}{(n-1)!} \lim_{z \to a}
  \fdif{^{n-1}}{z^{n-1}}((z-a)^nf(z)) \]
\end{mydef}

\annexe
\section{Dirac}
\label{app:dirac}
Un Dirac est une fonction avec singularité en 0.
Elle se note $\delta(x)$ et est définie par
\begin{equation}
  \label{eq:dirac1}
  \delta(x) =
  \begin{cases}
    \infty, & x = 0\\
    0, & x \neq 0
  \end{cases}
\end{equation}
et
\begin{equation}
  \label{eq:dirac2}
  \int_{-\infty}^{\infty} \delta(x) \dif x = 1.
\end{equation}

Ça peut paraitre bizarre que l'intégrale soit finie alors que
$\delta(0) = \infty$.
Seulement, rappelez vous qu'une intégrale c'est une aire et que
l'aire d'un Dirac n'est pas entièrement définie par \eqref{eq:dirac1}
car celle ci impose que l'aire vaut $0 \cdot \infty$ qui est un cas
d'indétermination.
\eqref{eq:dirac2} permet de lever cette indétermination.

\end{document}
